name: Enhanced NeonHub CI/CD with Autonomous Testing

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run autonomous testing daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  POSTGRES_VERSION: '14'

jobs:
  setup:
    name: Environment Setup & Validation
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-deps.outputs.cache-hit }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Cache dependencies
        id: cache-deps
        uses: actions/cache@v3
        with:
          path: |
            node_modules
            ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-
            
      - name: Install dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: npm ci
        
      - name: Generate Prisma client
        run: npm run db:generate

  security-audit:
    name: Security Vulnerability Scan
    runs-on: ubuntu-latest
    needs: setup
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run security audit
        run: |
          npm audit --audit-level=moderate
          npm audit --production --audit-level=high
          
      - name: Upload security report
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: security-audit-report
          path: npm-audit-report.json

  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    needs: setup
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run ESLint
        run: npm run lint
        
      - name: Check code formatting
        run: npm run format:check
        
      - name: TypeScript compilation check
        run: npm run type-check

  unit-tests:
    name: Unit Tests & Coverage
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: neonhub_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Setup test database
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/neonhub_test
        run: |
          npm run db:generate
          npm run db:push
          
      - name: Run unit tests with coverage
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/neonhub_test
        run: npm run test:coverage
        
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          
      - name: Coverage report comment
        if: github.event_name == 'pull_request'
        uses: romeovs/lcov-reporter-action@v0.3.1
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          lcov-file: ./coverage/lcov.info

  api-contract-validation:
    name: API Contract Validation
    runs-on: ubuntu-latest
    needs: [setup, unit-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Generate Prisma client
        run: npm run db:generate
        
      - name: Validate API contracts
        run: npm run validate:api
        
      - name: Upload API validation report
        uses: actions/upload-artifact@v4
        with:
          name: api-contract-report
          path: api-contract-validation-report.md

  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [setup, unit-tests]
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: neonhub_e2e
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Install Playwright browsers
        run: npx playwright install --with-deps
        
      - name: Setup E2E database
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/neonhub_e2e
        run: |
          npm run db:generate
          npm run db:push
          
      - name: Build applications
        run: npm run build
        
      - name: Run E2E tests
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/neonhub_e2e
        run: npm run test:e2e
        
      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: playwright-report/
          retention-days: 30

  autonomous-testing:
    name: Autonomous Testing & Fine-Tuning
    runs-on: ubuntu-latest
    needs: [setup, code-quality, unit-tests, api-contract-validation]
    if: github.event_name == 'schedule' || github.ref == 'refs/heads/main'
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: neonhub_autonomous
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Setup autonomous testing database
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/neonhub_autonomous
        run: |
          npm run db:generate
          npm run db:push
          
      - name: Run autonomous testing agent
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/neonhub_autonomous
        run: npm run test:autonomous
        
      - name: Run fine-tuning master
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/neonhub_autonomous
        run: npm run fine-tune
        
      - name: Upload autonomous testing reports
        uses: actions/upload-artifact@v4
        with:
          name: autonomous-testing-reports
          path: |
            autonomous-testing-report.md
            FINE_TUNING_MASTER_REPORT.md
          retention-days: 30
          
      - name: Create issue for critical findings
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let reportContent = '';
            
            try {
              reportContent = fs.readFileSync('FINE_TUNING_MASTER_REPORT.md', 'utf8');
            } catch (error) {
              reportContent = 'Autonomous testing failed to generate report';
            }
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® Critical Issues Found by Autonomous Testing - ${new Date().toISOString().split('T')[0]}`,
              body: `## Autonomous Testing Alert
            
            Critical issues have been detected by the autonomous testing system.
            
            **Timestamp**: ${new Date().toISOString()}
            **Trigger**: ${context.eventName}
            **Branch**: ${context.ref}
            
            ## Report Summary
            
            \`\`\`
            ${reportContent.slice(0, 2000)}${reportContent.length > 2000 ? '\n... (truncated)' : ''}
            \`\`\`
            
            Please review the full report in the workflow artifacts and address critical issues immediately.
            
            **Next Steps:**
            1. Download and review the autonomous testing reports
            2. Address all critical and high-priority issues
            3. Run the fine-tuning recommendations
            4. Close this issue once resolved
            `,
              labels: ['bug', 'critical', 'automated', 'needs-attention']
            });

  build-validation:
    name: Build Validation
    runs-on: ubuntu-latest
    needs: [setup, code-quality, unit-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Generate Prisma client
        run: npm run db:generate
        
      - name: Build applications
        run: npm run build
        
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            apps/*/dist/
            apps/*/.next/
          retention-days: 7

  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: [build-validation]
    if: github.event_name == 'pull_request' || github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run performance benchmarks
        run: |
          # Measure build time
          time npm run build
          
          # Measure bundle sizes (if available)
          if [ -f "apps/dashboard/.next/bundle-analyzer-report.json" ]; then
            echo "Dashboard bundle size analysis available"
          fi
          
      - name: Comment performance results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const comment = `## üìä Performance Benchmark Results
            
            Build completed successfully! ‚úÖ
            
            **Metrics:**
            - Build time: Measured in workflow
            - Bundle analysis: Available in artifacts
            
            **Next Steps:**
            - Review bundle size changes
            - Check for performance regressions
            - Consider optimization opportunities
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  deployment-readiness:
    name: Deployment Readiness Check
    runs-on: ubuntu-latest
    needs: [security-audit, code-quality, unit-tests, api-contract-validation, e2e-tests, build-validation]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Deployment readiness summary
        run: |
          echo "üéâ All checks passed! Deployment ready."
          echo "‚úÖ Security audit completed"
          echo "‚úÖ Code quality checks passed"
          echo "‚úÖ Unit tests passed"
          echo "‚úÖ API contracts validated"
          echo "‚úÖ E2E tests passed"
          echo "‚úÖ Build validation successful"
          
      - name: Trigger deployment
        run: |
          echo "üöÄ Ready for deployment to production"
          # Add your deployment trigger here
          # e.g., call deployment webhook, trigger CD pipeline, etc.

  cleanup:
    name: Cleanup & Notifications
    runs-on: ubuntu-latest
    needs: [deployment-readiness, autonomous-testing]
    if: always()
    
    steps:
      - name: Workflow summary
        run: |
          echo "## Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: ${{ github.ref }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          
      - name: Notify on failure
        if: failure()
        run: |
          echo "‚ùå Workflow failed. Please check the logs and fix issues."
          # Add notification logic here (Slack, email, etc.)